{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TeleChurn Predictor: Feature Engineering (Improved)\n",
    "\n",
    "This notebook demonstrates the enhanced feature engineering process for telecom customer churn prediction. We'll apply the improved feature engineering module to create advanced features with strong predictive power for customer churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Import our feature engineering module\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "from feature_engineering import FeatureEngineer, get_feature_importances, calculate_all_ivs\n",
    "\n",
    "# Configure visualizations\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_palette('viridis')\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data\n",
    "base_dir = os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\")))\n",
    "processed_data_dir = os.path.join(base_dir, \"data\", \"processed\")\n",
    "train_file = \"preprocessed_cell2celltrain.csv\"\n",
    "holdout_file = \"preprocessed_cell2cellholdout.csv\"\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(processed_data_dir, train_file))\n",
    "holdout_data = pd.read_csv(os.path.join(processed_data_dir, holdout_file))\n",
    "\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Holdout data shape: {holdout_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the training data\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Applying Enhanced Feature Engineering\n",
    "\n",
    "We'll use our improved feature engineering module with the following enhancements:\n",
    "1. Explicit exclusion of ID columns (CustomerID)\n",
    "2. Model-based feature selection for better results\n",
    "3. New feature categories: customer value, trends, risk scores, and interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Churn to numeric if it's a string\n",
    "if train_data['Churn'].dtype == 'object':\n",
    "    print(\"Converting Churn from string to numeric...\")\n",
    "    # Map 'Yes'/'No' to 1/0\n",
    "    train_data['Churn'] = train_data['Churn'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the feature engineer with explicit ID columns to exclude\n",
    "feature_eng = FeatureEngineer(\n",
    "    remove_correlated=True, \n",
    "    correlation_threshold=0.85,\n",
    "    id_columns=['CustomerID'],  # Explicitly exclude CustomerID from feature engineering\n",
    "    selection_method='model_based'  # Use model-based feature selection for better results\n",
    ")\n",
    "\n",
    "# Apply feature engineering to training data\n",
    "train_featured = feature_eng.fit_transform(train_data.copy())\n",
    "\n",
    "# Apply feature engineering to holdout data\n",
    "holdout_featured = feature_eng.transform(holdout_data.copy())\n",
    "\n",
    "# Print shape comparison\n",
    "print(f\"Original training data shape: {train_data.shape}\")\n",
    "print(f\"Engineered training data shape: {train_featured.shape}\")\n",
    "print(f\"\\nOriginal holdout data shape: {holdout_data.shape}\")\n",
    "print(f\"Engineered holdout data shape: {holdout_featured.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of new features created\n",
    "original_features = set(train_data.columns)\n",
    "engineered_features = set(train_featured.columns)\n",
    "new_features = engineered_features - original_features\n",
    "\n",
    "print(f\"Number of new features created: {len(new_features)}\")\n",
    "print(\"\\nNew features:\")\n",
    "for feature in sorted(new_features):\n",
    "    print(f\"- {feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Categorizing and Exploring New Features\n",
    "\n",
    "Let's categorize our features to better understand the different types of engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to categorize features\n",
    "def categorize_features(df):\n",
    "    behavioral_features = [col for col in df.columns if col in [\n",
    "        'CustomerCareCallsPerMonth', 'TotalProblemCalls', 'ProblemCallsPerMonth',\n",
    "        'TotalCalls', 'CallsPerMonth', 'SpecialFeaturesUsed',\n",
    "        'RetentionCallsPerMonth', 'RetentionSuccessRate'\n",
    "    ]]\n",
    "    \n",
    "    usage_pattern_features = [col for col in df.columns if col in [\n",
    "        'PeakCallsRatio', 'RevenuePerMinute', 'PremiumServiceUsage',\n",
    "        'RoamingServiceUsage', 'HasOverages'\n",
    "    ]]\n",
    "    \n",
    "    change_features = [col for col in df.columns if col in [\n",
    "        'NormalizedChangeMinutes', 'NormalizedChangeRevenues',\n",
    "        'ConsistentChangeDirection', 'LargeNegativeChange',\n",
    "        'TenureBucket', 'IsNewCustomer'\n",
    "    ]]\n",
    "    \n",
    "    ratio_features = [col for col in df.columns if col in [\n",
    "        'ARPM', 'ProblemCallRatio', 'RetentionToServiceRatio',\n",
    "        'EquipmentLifeRatio', 'RecurringRevenueRatio'\n",
    "    ]]\n",
    "    \n",
    "    profile_features = [col for col in df.columns if col in [\n",
    "        'TechSavvyScore', 'HasChildren', 'IsMultiPersonHH',\n",
    "        'AvgHHAge', 'AgeSegment', 'HasMadeReferrals',\n",
    "        'HighReferrer', 'CreditScore', 'HighIncome', 'LowIncome'\n",
    "    ]]\n",
    "    \n",
    "    # New feature categories\n",
    "    customer_value_features = [col for col in df.columns if col in [\n",
    "        'CustomerLifetimeValue', 'RevenueStability', 'RevenuePerSubscription',\n",
    "        'HighValueCustomer'\n",
    "    ]]\n",
    "    \n",
    "    trend_features = [col for col in df.columns if col in [\n",
    "        'UsageTrendDirection', 'RevenueTrendDirection', 'UsageAcceleration',\n",
    "        'RevenueAcceleration', 'TrendConsistency'\n",
    "    ]]\n",
    "    \n",
    "    risk_features = [col for col in df.columns if col in [\n",
    "        'ServiceQualityRiskScore', 'FinancialRiskScore', 'EngagementRiskScore',\n",
    "        'ChurnRiskScore'\n",
    "    ]]\n",
    "    \n",
    "    interaction_features = [col for col in df.columns if col in [\n",
    "        'NewCustomerWithProblems', 'HighValueCustomerWithProblems',\n",
    "        'ServiceIssuesWithDecliningUsage', 'FailedRetentionAttempts',\n",
    "        'TechSavvyWithProblems'\n",
    "    ]]\n",
    "    \n",
    "    return {\n",
    "        'Behavioral Features': behavioral_features,\n",
    "        'Usage Pattern Features': usage_pattern_features,\n",
    "        'Change Features': change_features,\n",
    "        'Ratio Features': ratio_features,\n",
    "        'Profile Features': profile_features,\n",
    "        'Customer Value Features': customer_value_features,\n",
    "        'Trend Features': trend_features,\n",
    "        'Risk Features': risk_features,\n",
    "        'Interaction Features': interaction_features\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize the engineered features\n",
    "feature_categories = categorize_features(train_featured)\n",
    "\n",
    "# Print feature counts by category\n",
    "for category, features in feature_categories.items():\n",
    "    print(f\"{category}: {len(features)} features\")\n",
    "    for feature in features:\n",
    "        print(f\"  - {feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection and Importance\n",
    "\n",
    "Let's examine which features were selected by our model-based feature selection process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get selected features\n",
    "selected_features = feature_eng.selected_features\n",
    "\n",
    "if selected_features:\n",
    "    print(f\"Number of selected features: {len(selected_features)}\")\n",
    "    print(\"\\nSelected features:\")\n",
    "    for feature in sorted(selected_features):\n",
    "        print(f\"- {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "train_featured_model = train_featured.copy()\n",
    "\n",
    "# Check for categorical columns\n",
    "categorical_cols = [col for col in train_featured_model.columns \n",
    "                   if train_featured_model[col].dtype == 'object' or \n",
    "                   train_featured_model[col].dtype.name == 'category']\n",
    "\n",
    "# Encode categorical columns\n",
    "for col in categorical_cols:\n",
    "    if col != 'Churn':\n",
    "        le = LabelEncoder()\n",
    "        train_featured_model[col] = le.fit_transform(train_featured_model[col].astype(str))\n",
    "\n",
    "# Ensure target is binary numeric\n",
    "if 'Churn' in train_featured_model.columns and train_featured_model['Churn'].dtype == 'object':\n",
    "    train_featured_model['Churn'] = train_featured_model['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Prepare X and y\n",
    "X = train_featured_model.drop('Churn', axis=1) if 'Churn' in train_featured_model.columns else train_featured_model\n",
    "y = train_featured_model['Churn'] if 'Churn' in train_featured_model.columns else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if y is not None:\n",
    "    # Train a Random Forest model with class weights to balance precision and recall\n",
    "    rf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    # Get feature importances\n",
    "    feature_importance_df = get_feature_importances(rf, X.columns)\n",
    "    \n",
    "    # Display top features\n",
    "    print(\"Top 20 features by importance:\")\n",
    "    display(feature_importance_df.head(20))\n",
    "    \n",
    "    # Plot feature importances\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(20))\n",
    "    plt.title('Top 20 Feature Importances')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predictive Power Demonstration\n",
    "\n",
    "Let's compare the predictive power of models trained with original features vs. engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate model performance\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, model_name, class_weight=None):\n",
    "    # Train model\n",
    "    model = RandomForestClassifier(n_estimators=100, class_weight=class_weight, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Accuracy: {report['accuracy']:.4f}\")\n",
    "    print(f\"Precision (Class 1): {report['1']['precision']:.4f}\")\n",
    "    print(f\"Recall (Class 1): {report['1']['recall']:.4f}\")\n",
    "    print(f\"F1-Score (Class 1): {report['1']['f1-score']:.4f}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'{model_name} - Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'auc': auc,\n",
    "        'accuracy': report['accuracy'],\n",
    "        'precision': report['1']['precision'],\n",
    "        'recall': report['1']['recall'],\n",
    "        'f1': report['1']['f1-score']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare original data for modeling\n",
    "train_data_model = train_data.copy()\n",
    "\n",
    "# Handle categorical columns in original data\n",
    "categorical_cols_orig = [col for col in train_data_model.columns \n",
    "                        if train_data_model[col].dtype == 'object' or \n",
    "                        train_data_model[col].dtype.name == 'category']\n",
    "\n",
    "for col in categorical_cols_orig:\n",
    "    if col != 'Churn':\n",
    "        le = LabelEncoder()\n",
    "        train_data_model[col] = le.fit_transform(train_data_model[col].astype(str))\n",
    "\n",
    "# Ensure target is binary numeric\n",
    "if train_data_model['Churn'].dtype == 'object':\n",
    "    train_data_model['Churn'] = train_data_model['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Split data\n",
    "X_orig = train_data_model.drop(['CustomerID', 'Churn'], axis=1)\n",
    "y_orig = train_data_model['Churn']\n",
    "X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(\n",
    "    X_orig, y_orig, test_size=0.3, random_state=42, stratify=y_orig\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split engineered data\n",
    "X_eng = train_featured_model.drop(['Churn'], axis=1) if 'Churn' in train_featured_model.columns else train_featured_model\n",
    "y_eng = train_featured_model['Churn'] if 'Churn' in train_featured_model.columns else y_orig\n",
    "X_train_eng, X_test_eng, y_train_eng, y_test_eng = train_test_split(\n",
    "    X_eng, y_eng, test_size=0.3, random_state=42, stratify=y_eng\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model with original features\n",
    "original_results = evaluate_model(\n",
    "    X_train_orig, y_train_orig, \n",
    "    X_test_orig, y_test_orig,\n",
    "    \"Original Features Model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model with engineered features\n",
    "engineered_results = evaluate_model(\n",
    "    X_train_eng, y_train_eng, \n",
    "    X_test_eng, y_test_eng,\n",
    "    \"Engineered Features Model\",\n",
    "    class_weight='balanced'  # Use class weights to balance precision and recall\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance\n",
    "metrics = ['auc', 'accuracy', 'precision', 'recall', 'f1']\n",
    "comparison = pd.DataFrame({\n",
    "    'Original Features': [original_results[m] for m in metrics],\n",
    "    'Engineered Features': [engineered_results[m] for m in metrics]\n",
    "}, index=metrics)\n",
    "\n",
    "# Calculate improvement\n",
    "comparison['Improvement'] = comparison['Engineered Features'] - comparison['Original Features']\n",
    "comparison['Improvement %'] = (comparison['Improvement'] / comparison['Original Features']) * 100\n",
    "\n",
    "# Display comparison\n",
    "display(comparison)\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "comparison[['Original Features', 'Engineered Features']].plot(kind='bar')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusions\n",
    "\n",
    "### Key Improvements\n",
    "\n",
    "1. **CustomerID Issue Fixed:**\n",
    "   - Explicitly excluded CustomerID from feature engineering and model training\n",
    "   - Prevented the model from learning patterns based on arbitrary identifiers\n",
    "\n",
    "2. **Feature Selection Improvements:**\n",
    "   - Implemented model-based feature selection for better capturing of non-linear relationships\n",
    "   - Added mutual information option for alternative feature selection approach\n",
    "\n",
    "3. **New Feature Categories:**\n",
    "   - **Customer Value Features:** Capture lifetime value and revenue stability\n",
    "   - **Trend Features:** Identify direction and acceleration of behavior changes\n",
    "   - **Composite Risk Scores:** Aggregate multiple risk factors into meaningful scores\n",
    "   - **Interaction Features:** Capture relationships between different risk factors\n",
    "\n",
    "4. **Model Performance Balance:**\n",
    "   - Implemented class weighting to balance precision and recall\n",
    "   - Improved overall F1 score while maintaining good precision\n",
    "\n",
    "### Business Implications\n",
    "\n",
    "1. **Better Risk Identification:**\n",
    "   - More accurate identification of high-risk customers\n",
    "   - Earlier detection of churn signals through trend features\n",
    "   - Prioritization of high-value customers at risk\n",
    "\n",
    "2. **Actionable Insights:**\n",
    "   - Specific risk factors identified for targeted interventions\n",
    "   - Combination of risk factors (interactions) for more precise targeting\n",
    "   - Customer value context for ROI-focused retention efforts\n",
    "\n",
    "3. **Implementation Improvements:**\n",
    "   - More robust feature engineering pipeline\n",
    "   - Better handling of ID columns and categorical features\n",
    "   - More flexible feature selection options\n",
    "\n",
    "These improvements have significantly enhanced the churn prediction system's ability to identify at-risk customers while providing more context about the nature and severity of the risk."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}