{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telecom Customer Churn Prediction - Model Deployment\n",
    "\n",
    "This notebook demonstrates how to load trained models and use them for prediction on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Add the scripts directory to the path\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "# Import our modules\n",
    "from base_model import BaseModel\n",
    "from gradient_boosting import XGBoostModel, LightGBMModel\n",
    "from neural_network import NeuralNetworkModel\n",
    "from training_pipeline import ModelTrainer\n",
    "from utils import align_features\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the preprocessed data\n",
    "X_train = pd.read_csv('../data/processed/X_train.csv')\n",
    "y_train = pd.read_csv('../data/processed/y_train.csv', squeeze=True)\n",
    "X_val = pd.read_csv('../data/processed/X_val.csv')\n",
    "y_val = pd.read_csv('../data/processed/y_val.csv', squeeze=True)\n",
    "X_holdout = pd.read_csv('../data/processed/X_holdout.csv')\n",
    "y_holdout = pd.read_csv('../data/processed/y_holdout.csv', squeeze=True)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"Holdout set: {X_holdout.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the Best Model\n",
    "\n",
    "Based on our previous evaluation, we'll load the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define the model path - update this with your best model\n",
    "model_path = '../models/XGBoost_Churn_Predictor'\n",
    "\n",
    "# Load the model\n",
    "best_model = XGBoostModel.load_model(model_path)\n",
    "print(f\"Loaded model: {best_model.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Align Features for Prediction\n",
    "\n",
    "Before making predictions, we need to ensure that the features in our holdout set match those used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check for feature differences\n",
    "train_features = set(X_train.columns)\n",
    "holdout_features = set(X_holdout.columns)\n",
    "\n",
    "print(f\"Number of features in training set: {len(train_features)}\")\n",
    "print(f\"Number of features in holdout set: {len(holdout_features)}\")\n",
    "print(f\"Features in training but not in holdout: {train_features - holdout_features}\")\n",
    "print(f\"Features in holdout but not in training: {holdout_features - train_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Align the holdout features with the training features\n",
    "X_holdout_aligned = align_features(X_train, X_holdout)\n",
    "\n",
    "# Verify the alignment\n",
    "print(f\"Aligned holdout set shape: {X_holdout_aligned.shape}\")\n",
    "print(f\"Features match training set: {list(X_train.columns) == list(X_holdout_aligned.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make Predictions on Holdout Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get the optimal threshold from previous evaluation\n",
    "# You can load this from the saved model history or set it manually\n",
    "optimal_threshold = 0.38  # Update this with your optimal threshold\n",
    "\n",
    "# Make predictions\n",
    "y_pred_proba = best_model.predict_proba(X_holdout_aligned)[:, 1]\n",
    "y_pred = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "# Create a prediction dataframe\n",
    "predictions_df = pd.DataFrame({\n",
    "    'customer_id': X_holdout_aligned.index if 'CustomerID' not in X_holdout_aligned.columns else X_holdout_aligned['CustomerID'],\n",
    "    'churn_probability': y_pred_proba,\n",
    "    'predicted_churn': y_pred\n",
    "})\n",
    "\n",
    "# Display the first few predictions\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Predictions on Holdout Set\n",
    "\n",
    "If we have the ground truth for the holdout set, we can evaluate our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "if y_holdout is not None:\n",
    "    # Calculate metrics\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_holdout, y_pred))\n",
    "    \n",
    "    # Calculate AUC\n",
    "    auc = roc_auc_score(y_holdout, y_pred_proba)\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = confusion_matrix(y_holdout, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "                xticklabels=['No Churn', 'Churn'],\n",
    "                yticklabels=['No Churn', 'Churn'])\n",
    "    plt.title(f\"Confusion Matrix (Threshold={optimal_threshold:.2f})\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No ground truth available for holdout set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Identify High-Risk Customers\n",
    "\n",
    "Let's identify customers with the highest churn probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Sort by churn probability in descending order\n",
    "high_risk_customers = predictions_df.sort_values('churn_probability', ascending=False).head(20)\n",
    "high_risk_customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis\n",
    "\n",
    "Let's examine which features are most important for predicting churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot feature importance\n",
    "if hasattr(best_model, 'plot_feature_importance'):\n",
    "    importance_df = best_model.plot_feature_importance(X_train, y_train, top_n=20)\n",
    "    importance_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Predictions\n",
    "\n",
    "Finally, let's save our predictions for further analysis or deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save predictions to CSV\n",
    "predictions_df.to_csv('../data/predictions/holdout_predictions.csv', index=False)\n",
    "print(\"Predictions saved to '../data/predictions/holdout_predictions.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}