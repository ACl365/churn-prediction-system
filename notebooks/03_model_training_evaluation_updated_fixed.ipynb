{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telecom Customer Churn Prediction - Model Training and Evaluation\n",
    "\n",
    "This notebook demonstrates the training and evaluation of machine learning models for predicting customer churn in a telecom company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the scripts directory to the path\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "# Import our modules\n",
    "from base_model import BaseModel\n",
    "from gradient_boosting import XGBoostModel, LightGBMModel\n",
    "from neural_network import NeuralNetworkModel\n",
    "from training_pipeline import ModelTrainer, compare_models\n",
    "from utils import align_features\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data\n",
    "X_train = pd.read_csv('../data/processed/X_train.csv')\n",
    "y_train = pd.read_csv('../data/processed/y_train.csv').iloc[:, 0]  # Use iloc instead of squeeze\n",
    "X_val = pd.read_csv('../data/processed/X_val.csv')\n",
    "y_val = pd.read_csv('../data/processed/y_val.csv').iloc[:, 0]  # Use iloc instead of squeeze\n",
    "X_holdout = pd.read_csv('../data/processed/X_holdout.csv')\n",
    "y_holdout = pd.read_csv('../data/processed/y_holdout.csv').iloc[:, 0]  # Use iloc instead of squeeze\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"Holdout set: {X_holdout.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Models\n",
    "\n",
    "We'll train and compare three different models:\n",
    "1. XGBoost\n",
    "2. LightGBM\n",
    "3. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize XGBoost model\n",
    "xgb_model = XGBoostModel(\n",
    "    model_name=\"XGBoost_Churn_Predictor\",\n",
    "    params={\n",
    "        'max_depth': 5,\n",
    "        'learning_rate': 0.1,\n",
    "        'n_estimators': 100,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'use_label_encoder': False\n",
    "    },\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Initialize LightGBM model\n",
    "lgb_model = LightGBMModel(\n",
    "    model_name=\"LightGBM_Churn_Predictor\",\n",
    "    params={\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.1,\n",
    "        'n_estimators': 100,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc'\n",
    "    },\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Initialize Neural Network model\n",
    "nn_model = NeuralNetworkModel(\n",
    "    model_name=\"NeuralNetwork_Churn_Predictor\",\n",
    "    hidden_layers=[64, 32, 16],\n",
    "    activations='relu',\n",
    "    dropout_rate=0.3,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    early_stopping_patience=10,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Model Trainers with SMOTE Resampling\n",
    "\n",
    "We'll use SMOTE (Synthetic Minority Over-sampling Technique) to handle class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainers with SMOTE resampling\n",
    "xgb_trainer = ModelTrainer(\n",
    "    model=xgb_model,\n",
    "    resampling_strategy='smote',\n",
    "    resampling_ratio=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgb_trainer = ModelTrainer(\n",
    "    model=lgb_model,\n",
    "    resampling_strategy='smote',\n",
    "    resampling_ratio=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "nn_trainer = ModelTrainer(\n",
    "    model=nn_model,\n",
    "    resampling_strategy='smote',\n",
    "    resampling_ratio=0.5,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train and Evaluate XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training pipeline for XGBoost\n",
    "xgb_results = xgb_trainer.run_training_pipeline(\n",
    "    X_train, y_train,\n",
    "    tune_hyperparameters=False,\n",
    "    tune_threshold=True,\n",
    "    cross_validate=True,\n",
    "    cv=5,\n",
    "    save_model=True,\n",
    "    save_history=True,\n",
    "    plot_cm=True,\n",
    "    plot_roc=True,\n",
    "    plot_pr=True,\n",
    "    plot_prob_dist=True,\n",
    "    plot_importance=True,\n",
    "    importance_top_n=20,\n",
    "    threshold_metric='f1'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train and Evaluate LightGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training pipeline for LightGBM\n",
    "lgb_results = lgb_trainer.run_training_pipeline(\n",
    "    X_train, y_train,\n",
    "    tune_hyperparameters=False,\n",
    "    tune_threshold=True,\n",
    "    cross_validate=True,\n",
    "    cv=5,\n",
    "    save_model=True,\n",
    "    save_history=True,\n",
    "    plot_cm=True,\n",
    "    plot_roc=True,\n",
    "    plot_pr=True,\n",
    "    plot_prob_dist=True,\n",
    "    plot_importance=True,\n",
    "    importance_top_n=20,\n",
    "    threshold_metric='f1'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train and Evaluate Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training pipeline for Neural Network\n",
    "nn_results = nn_trainer.run_training_pipeline(\n",
    "    X_train, y_train,\n",
    "    tune_hyperparameters=False,\n",
    "    tune_threshold=True,\n",
    "    cross_validate=True,\n",
    "    cv=5,\n",
    "    save_model=True,\n",
    "    save_history=True,\n",
    "    plot_cm=True,\n",
    "    plot_roc=True,\n",
    "    plot_pr=True,\n",
    "    plot_prob_dist=True,\n",
    "    plot_importance=True,  # Will use permutation importance\n",
    "    importance_top_n=20,\n",
    "    threshold_metric='f1',\n",
    "    train_params={\n",
    "        'validation_split': 0.2,\n",
    "        'verbose': 1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "trainers = [xgb_trainer, lgb_trainer, nn_trainer]\n",
    "comparison_df = compare_models(\n",
    "    trainers=trainers,\n",
    "    X=X_val,\n",
    "    y=y_val,\n",
    "    test_size=0.0,  # Use the entire validation set\n",
    "    metrics=['accuracy', 'precision', 'recall', 'f1', 'auc'],\n",
    "    plot=True,\n",
    "    figsize=(14, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the best model based on F1 score\n",
    "best_model_name = comparison_df.loc['f1'].idxmax()\n",
    "print(f\"Best model based on F1 score: {best_model_name}\")\n",
    "\n",
    "# Get the corresponding trainer\n",
    "if best_model_name == 'XGBoost_Churn_Predictor':\n",
    "    best_trainer = xgb_trainer\n",
    "elif best_model_name == 'LightGBM_Churn_Predictor':\n",
    "    best_trainer = lgb_trainer\n",
    "else:\n",
    "    best_trainer = nn_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate on Holdout Set\n",
    "\n",
    "Now we'll evaluate the best model on the holdout set. First, we need to align the features between the training and holdout sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for feature differences\n",
    "train_features = set(X_train.columns)\n",
    "holdout_features = set(X_holdout.columns)\n",
    "\n",
    "print(f\"Number of features in training set: {len(train_features)}\")\n",
    "print(f\"Number of features in holdout set: {len(holdout_features)}\")\n",
    "print(f\"Features in training but not in holdout: {train_features - holdout_features}\")\n",
    "print(f\"Features in holdout but not in training: {holdout_features - train_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align the holdout features with the training features\n",
    "X_holdout_aligned = align_features(X_train, X_holdout)\n",
    "\n",
    "# Verify the alignment\n",
    "print(f\"Aligned holdout set shape: {X_holdout_aligned.shape}\")\n",
    "print(f\"Features match training set: {list(X_train.columns) == list(X_holdout_aligned.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model on the holdout set\n",
    "if y_holdout is not None:\n",
    "    # Get the optimal threshold from validation\n",
    "    optimal_threshold = best_trainer.training_history.get('optimal_threshold', {}).get('value', 0.5)\n",
    "\n",
    "    print(f\"Using optimal threshold: {optimal_threshold:.4f}\")\n",
    "\n",
    "    # Evaluate on holdout set\n",
    "    holdout_metrics = best_trainer.evaluate_model(X_holdout_aligned, y_holdout, threshold=optimal_threshold)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    best_trainer.plot_confusion_matrix(X_holdout_aligned, y_holdout, threshold=optimal_threshold)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    best_trainer.plot_roc_curve(X_holdout_aligned, y_holdout)\n",
    "\n",
    "    # Plot Precision-Recall curve\n",
    "    best_trainer.plot_precision_recall_curve(X_holdout_aligned, y_holdout)\n",
    "else:\n",
    "    print(\"Holdout set does not have target labels for evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save the Best Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model for deployment\n",
    "best_model_path = best_trainer.model.save_model(model_dir='../models/deployment')\n",
    "print(f\"Best model saved to: {best_model_path}\")\n",
    "\n",
    "# Save the optimal threshold\n",
    "import json\n",
    "threshold_info = {\n",
    "    'model_name': best_trainer.model.model_name,\n",
    "    'optimal_threshold': optimal_threshold,\n",
    "    'metrics': holdout_metrics\n",
    "}\n",
    "\n",
    "with open(f\"../models/deployment/{best_trainer.model.model_name}_threshold.json\", 'w') as f:\n",
    "    json.dump(threshold_info, f, indent=4)\n",
    "\n",
    "print(f\"Threshold information saved to: ../models/deployment/{best_trainer.model.model_name}_threshold.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}